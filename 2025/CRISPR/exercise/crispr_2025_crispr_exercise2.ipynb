{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This file is part of the CRISPRsummerschool 2025 exercises\n",
        "\n",
        "Copyright (c) 2023-25 Christian Anthon\n",
        "\n",
        "This program is free software: you can redistribute it and/or modify\n",
        "it under the terms of the GNU General Public License as published by\n",
        "the Free Software Foundation, version 3.\n",
        "# Extracting features from the deep learning results\n",
        "Below you will find the second exercise.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RTH-tools/CRISPRsummerschool/blob/main/2025/CRISPR/exercise/crispr_2025_crispr_exercise2.ipynb)\n",
        "\n",
        "Deep learning does not easily lend itself to extraction of feature importance, like in the example of CRISPR where one could wish to know the importance of *e.g.* the first nucleotide of the NGG pam for the efficiency of the guide. In this exercise we will look at a way around this problem by masking out parts of the input sequence or of the energy parameter from the model input.\n"
      ],
      "metadata": {
        "id": "kgxfc01DPsu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## basic code definitions\n",
        "Enter the cell below and press play or Ctrl+Enter in the block below to execute. You should see the message \"Definitions executed\" printed after execution."
      ],
      "metadata": {
        "id": "_VlCGr5Czx5F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arbQedj7cIF0"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "from google.colab import drive\n",
        "from random import randint\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import pickle\n",
        "import urllib3\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import models, callbacks, Model, Input, utils, metrics\n",
        "from tensorflow.keras.layers import Conv1D, Dropout, Flatten, Dense, concatenate\n",
        "\n",
        "eLENGTH30 = 30\n",
        "eDEPTH = 4\n",
        "# Function to onehot encode the data\n",
        "def onehot(x):\n",
        "    z = list()\n",
        "    for y in list(x):\n",
        "        if y in \"Aa\":\n",
        "            z.append(0)\n",
        "        elif y in \"Cc\":\n",
        "            z.append(1)\n",
        "        elif y in \"Gg\":\n",
        "            z.append(2)\n",
        "        elif y in \"TtUu\":\n",
        "            z.append(3)\n",
        "        else:\n",
        "            print(\"Non-ATGCU character in\", x)\n",
        "            raise Exception\n",
        "    return z\n",
        "\n",
        "# Function to set the data into the appropriate format\n",
        "def set_data(DX, s, mask=None):\n",
        "  #mask should be a list length len(s) consisting of 1s and 0s, only positions where mask is 0 will be onehot encoded, those with 1s will be masked out.\n",
        "    if s is None:\n",
        "        return\n",
        "    assert(mask==None or (type(mask) is list and len(mask) == len(s)))\n",
        "    if type(mask) is list:\n",
        "        for j, x in enumerate(onehot(s)):\n",
        "            if mask[j] == 0:\n",
        "                DX[j][x] = 1\n",
        "    else:\n",
        "        for j, x in enumerate(onehot(s)):\n",
        "            DX[j][x] = 1\n",
        "\n",
        "\n",
        "# Preprocessing function for the sequence data\n",
        "def preprocess_seq(data, mask=None, use_dgb=True):\n",
        "    DATA_X30 = np.zeros((len(data), eLENGTH30, eDEPTH), dtype=np.float32)  # onehot\n",
        "    DATA_G = np.zeros((len(data), 1), dtype=np.float32)  # deltaGb\n",
        "    DATA_Y = np.zeros((len(data)), dtype=np.float32)  # efficiency\n",
        "\n",
        "    for l, d in enumerate(data):\n",
        "        set_data(DATA_X30[l], d[1], mask)\n",
        "        if use_dgb:\n",
        "            DATA_G[l] = -d[2]\n",
        "        DATA_Y[l] = d[3]\n",
        "    return (DATA_X30, DATA_G, DATA_Y)\n",
        "\n",
        "#commands run to download data\n",
        "#You may need to change the URL to a suitable one outside of github due to ratelimits\n",
        "! [[ -e training_data.csv ]] || curl -o training_data.csv https://rth.dk/internal/index.php/s/ypWRwznx6fXFjZN/download\n",
        "! [[ -e validation_data.csv ]] || curl -o validation_data.csv https://rth.dk/internal/index.php/s/KR9opRTe8EkXNyi/download\n",
        "\n",
        "\n",
        "# Training Data\n",
        "PATH = './'\n",
        "# x30 - onehot encoded 30mer\n",
        "# g - deltaGb\n",
        "# y - the efficiency value [0-100] )\n",
        "\n",
        "# Training Data\n",
        "PATH = './'\n",
        "d = pandas.read_csv(PATH + 'training_data.csv').values.tolist()\n",
        "(x30, g, y) = preprocess_seq(d)\n",
        "\n",
        "#Validation data read\n",
        "dv = pandas.read_csv(PATH + 'validation_data.csv').values.tolist()\n",
        "(x30v, gv, yv) = preprocess_seq(dv)\n",
        "\n",
        "print('Data loaded')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model definition and baseline performance (5-10 minutes)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In the code below, we will re-use the simplified version of the CRISPRon ontarget model we created in the previous exercise, but we will preprocess the data in different ways, by masking out information from the input in order to glean its relative importance."
      ],
      "metadata": {
        "id": "_XNx_2qf8-20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPT = 'adam' #use the ADAM optizer\n",
        "LOSS = 'mse' #loss function is mean squared error\n",
        "\n",
        "DROPOUT_DENSE = 0.3\n",
        "\n",
        "\n",
        "CONV_1_SIZE = 3\n",
        "N_CONV_1 = 40\n",
        "N_DENSE = 40\n",
        "N_OUT = 40\n",
        "\n",
        "# Inputs\n",
        "inputs_30 = list()\n",
        "\n",
        "inputs_c_30 = Input(shape=(eLENGTH30, eDEPTH), name=\"inputs_onehot_30\")\n",
        "inputs_30.append(inputs_c_30)\n",
        "inputs_g = Input(shape=(1,), name=\"inputs_dgb_on\")\n",
        "inputs_30.append(inputs_g)\n",
        "\n",
        "# Model_30 layers\n",
        "for_dense_30 = list()\n",
        "\n",
        "# First convolution layer\n",
        "conv1_out_30 = Conv1D(N_CONV_1, CONV_1_SIZE, activation='relu', input_shape=(eLENGTH30, eDEPTH), name=\"conv_3_30\")(inputs_c_30)\n",
        "conv1_flatten_out_30 = Flatten(name=\"flatten_3_30\")(conv1_out_30)\n",
        "for_dense_30.append(conv1_flatten_out_30)\n",
        "\n",
        "# Concatenation of conv layers and deltaGb layer\n",
        "concat_out_30 = concatenate(for_dense_30, name=\"concat_cnv_30\")\n",
        "\n",
        "# First dense (fully connected) layer\n",
        "dense0_out_30 = Dense(N_DENSE, activation='relu', name=\"dense_0_30\")(concat_out_30)\n",
        "dense0_dropout_out_30 = Dropout(DROPOUT_DENSE, name=\"drop_d0_30\")(dense0_out_30)\n",
        "\n",
        "# Gb input used raw\n",
        "concat1_out_30 = concatenate((inputs_g, dense0_dropout_out_30), name=\"concat_dgb_30\")\n",
        "\n",
        "# First dense (fully connected) layer\n",
        "dense1_out_30 = Dense(N_DENSE, activation='relu', name=\"dense_1_30\")(concat1_out_30)\n",
        "dense1_dropout_out_30 = Dropout(DROPOUT_DENSE, name=\"drop_d1_30\")(dense1_out_30)\n",
        "\n",
        "# Second dense (fully connected) layer\n",
        "dense2_out_30 = Dense(N_OUT, activation='relu', name=\"dense_2_30\")(dense1_dropout_out_30)\n",
        "dense2_dropout_out_30 = Dropout(DROPOUT_DENSE, name=\"drop_d2_30\")(dense2_out_30)\n",
        "\n",
        "# Output layer\n",
        "dense_on_off_out = Dense(N_OUT, activation='relu', name=\"dense_on_off\")(dense2_dropout_out_30)\n",
        "dense_on_off_dropout_out = Dropout(DROPOUT_DENSE, name=\"drop_d_on_off\")(dense_on_off_out)\n",
        "output_30 = Dense(1, name=\"output_30\")(dense_on_off_dropout_out)\n",
        "\n",
        "# Model_30\n",
        "postfix = '.model_30'\n",
        "inputs = inputs_30\n",
        "outputs = [output_30]\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss=LOSS, optimizer=OPT, metrics=['mae', 'mse'])\n",
        "\n",
        "\n",
        "print('Model defined')"
      ],
      "metadata": {
        "id": "IAoPTfp6Urcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7_vN6XA9eBkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing\n",
        "First we preprocess the data in the same way as for exercise 1 and execute the model **training** to initialize weights for later use. Check that you get more or less the same result as in exercise 1 (mse in the range of 160-162 on the validation data)."
      ],
      "metadata": {
        "id": "TUiH-5qVUG8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training data preprocess\n",
        "(x30, g, y) = preprocess_seq(d)\n",
        "#Validation data preprocess\n",
        "(x30v, gv, yv) = preprocess_seq(dv)\n",
        "\n",
        "print(x30[0], g[0], y[0])\n",
        "\n",
        "print(\"training...\")\n",
        "\n",
        "OPT = 'adam' #use the ADAM optizer\n",
        "LEARN = 1e-4 #learning rate\n",
        "EPOCHS = 200 #maximum number of Epochs\n",
        "LOSS = 'mse' #loss function is mean squared error\n",
        "BATCH_SIZE = 64 #batch size for the training\n",
        "\n",
        "\n",
        "#early stopping is a way to control for overfitting and save the best model\n",
        "es = callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            min_delta=0.1,\n",
        "            patience=25,\n",
        "            verbose=1,\n",
        "            mode='auto',\n",
        "            restore_best_weights=True,\n",
        "            ),\n",
        "\n",
        "#save the initial weights to be able restart the training using the same weights each time\n",
        "model.save_weights('model_30.init.weights.h5')\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    (x30, g), y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=((x30v,gv), yv),\n",
        "    callbacks=[es],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "print(\"done\")\n",
        "\n",
        "print(\"evaluating validation data using best model weights\")\n",
        "model.evaluate((x30v,gv), yv)\n"
      ],
      "metadata": {
        "id": "U6T5hNSajv6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2.1\n",
        "Masking out input information to estimate its importance for the efficiency prediction.\n",
        "\n",
        "Below you are presented with ways of masking out the input information in either the sequence or by removing the energy parameter from the model.\n",
        "\n",
        "The ontarget sequence is stored as a 30mer sequence consisting of\n",
        "\n",
        "```\n",
        "4nt prefix + 20nt ontarget + 3nt NGG PAM + 3nt suffix\n",
        "```\n",
        "\n",
        "You can for example mask out the first three nucleotides by setting the first 4 values of ```mask``` to 1\n",
        "```\n",
        "mask = [1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "```\n",
        "or disable the use of the energy parameter by setting\n",
        "```\n",
        "use_dgb = False\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "tfBPA860iiUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "use_dgb = True\n",
        "#training data preprocess\n",
        "(x30, g, y) = preprocess_seq(d, mask, use_dgb)\n",
        "#Validation data preprocess\n",
        "(x30v, gv, yv) = preprocess_seq(dv, mask, use_dgb)\n",
        "\n",
        "print(x30[0], g[0], y[0])\n",
        "\n",
        "\n",
        "#restore the initial weights\n",
        "if os.path.exists('model_30.init.weights.h5'):\n",
        "  print('weights loaded')\n",
        "  model.load_weights('model_30.init.weights.h5')\n",
        "else:\n",
        "  #did you forget to train the the baseline model above?\n",
        "  raise Exception\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    (x30, g), y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=((x30v,gv), yv),\n",
        "    callbacks=[es],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "print(\"done\")\n",
        "print(\"evaulating validation data using best model weights\")\n",
        "model.evaluate((x30v,gv), yv)\n"
      ],
      "metadata": {
        "id": "HlAR_yvSGmWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.1.1\n",
        "Modify the code above to run the model without the energy parameter DGb and repeat the training 3-5 times.\n",
        "\n",
        "What is the effect on the performance?\n",
        "\n",
        "Is that effect smaller or larger than what is observed for the full model (mse 141.1 with DGb vs 145.1 without). Why would that be?\n"
      ],
      "metadata": {
        "id": "FZCsKpNH7O8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer"
      ],
      "metadata": {
        "id": "M7DjCgnrAEwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.1.2\n",
        "Modify the code above to mask out part of the ontarget sequence.\n",
        "\n",
        "What is the effect of masking out the GG of the NGG PAM?\n",
        "\n",
        "What is the effect of masking out all three nucleotides of the PAM?\n",
        "\n",
        "What is the effect of masking out first base just before them PAM?\n",
        "\n",
        " Does your answers depend on whether DGb is included in the model? For which of the three questions above would it be appropriate / inappropriate to include the energy parameter DGb?\n",
        "\n",
        " If time allows, come up with other parts of the sequence to mask out and check your expectation of the impact with the actual result?"
      ],
      "metadata": {
        "id": "XYgd4koh8j9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# answer"
      ],
      "metadata": {
        "id": "ortCMqO5AMXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2.2\n",
        "\n",
        "Suggest other features to include in the model, for example epigentic markers or adjusting the model for a particular type of CRISPR experiment?\n",
        "\n",
        "How would you incorporate them into the model?\n",
        "\n",
        "What could these features mean for the precision and generalizability of the model?\n"
      ],
      "metadata": {
        "id": "lACDGp3U-Bb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# answer"
      ],
      "metadata": {
        "id": "VgUyvZlnAPLG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
