{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RTH-tools/CRISPRsummerschool/blob/main/2025/CRISPR/exercise/crispr_2025_crispr_exercise4.ipynb)"
      ],
      "metadata": {
        "id": "PxLqEo-8VNMt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdajpKfsuE7X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, SimpleRNN, Dense, Dropout, Input, Attention, Add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "! [[ -e training_data.csv ]] || curl -o training_data.csv https://rth.dk/internal/index.php/s/ypWRwznx6fXFjZN/download\n",
        "! [[ -e validation_data.csv ]] || curl -o validation_data.csv https://rth.dk/internal/index.php/s/KR9opRTe8EkXNyi/download\n",
        "\n",
        "# Example sequence-to-integer mapping\n",
        "def encode_sequence(seq):\n",
        "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "    return [mapping[nucleotide] for nucleotide in seq]\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('training_data.csv')\n",
        "val_data = pd.read_csv('validation_data.csv')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Encode the 30-mer sequences\n",
        "X_train = np.array([encode_sequence(seq) for seq in data['target']])\n",
        "y_train = data['eff'].values\n",
        "\n",
        "X_val = np.array([encode_sequence(seq) for seq in val_data['target']])\n",
        "y_val = val_data['eff'].values\n",
        "\n",
        "\n",
        "# Split the data into training and test sets\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "\n",
        "# Parameters\n",
        "vocab_size = 4  # Number of unique nucleotides (A, C, G, T)\n",
        "embedding_dim = 32  # Size of the embedding vector\n",
        "input_length = 30  # Length of each sequence (30-mer)\n",
        "rnn_units = 64  # Number of units in the RNN layer\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(input_length,))\n",
        "\n",
        "# Embedding layer\n",
        "x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length)(inputs)\n",
        "\n",
        "# Bidirectional RNN layer\n",
        "x = Bidirectional(LSTM(units=rnn_units, return_sequences=True))(x)\n",
        "\n",
        "# Self-Attention mechanism\n",
        "attention = Attention()([x, x])\n",
        "x = Add()([x, attention])\n",
        "\n",
        "# Pooling the output of the RNN + Attention to feed into the Dense layer\n",
        "x = LSTM(units=rnn_units, return_sequences=False)(x)\n",
        "\n",
        "# Dropout layer for regularization\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Dense output layer\n",
        "x = Dense(120, activation=\"relu\")(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(120, activation=\"relu\")(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1)(x)\n",
        "# Model definition\n",
        "model = Model(inputs=inputs, outputs=[outputs, attention])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "es = callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            min_delta=0.1,\n",
        "            patience=10,\n",
        "            verbose=1,\n",
        "            mode='auto',\n",
        "            restore_best_weights=True,\n",
        "            ),\n",
        "\n",
        "# Training the model\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32,     callbacks=[es],)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eNe8G4C4_LvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred, attention_weights = model.predict(X_val)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "print(f'Mean Squared Error on Test Set: {mse}')"
      ],
      "metadata": {
        "id": "UGFYWTBu_IBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(attention_weights.shape)"
      ],
      "metadata": {
        "id": "Ic_87Q6zInJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Example: Visualizing attention weights for the first test sample\n",
        "for sample_index in range(20):\n",
        "  sequence = X_val[sample_index]\n",
        "  weights = attention_weights[sample_index]\n",
        "\n",
        "  # Plot attention weights\n",
        "  plt.figure(figsize=(10, 2))\n",
        "  sns.heatmap(weights, cmap='viridis')\n",
        "  plt.title(f'Attention Weights for Sample {sample_index} with eff {y_pred[sample_index]}')\n",
        "  plt.xlabel('Sequence Position')\n",
        "  plt.ylabel('Attention Weights')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "9x73PMYQIswh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ft4OPoXTOAxT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
