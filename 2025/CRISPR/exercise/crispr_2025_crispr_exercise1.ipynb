{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgxfc01DPsu9"
      },
      "source": [
        "This file is part of the CRISPRsummerschool 2025 exercises\n",
        "\n",
        "Copyright (c) 2023-25 Christian Anthon\n",
        "\n",
        "This program is free software: you can redistribute it and/or modify\n",
        "it under the terms of the GNU General Public License as published by\n",
        "the Free Software Foundation, version 3.\n",
        "# Warming up exercise\n",
        "Below you will find the first exercise, in which you will be introduced a small CRISPR on-target model in Tensorflow / Keras and use it to train a small ontarget efficiency model on real data.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RTH-tools/CRISPRsummerschool/blob/main/2025/CRISPR/exercise/crispr_2025_crispr_exercise1.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VlCGr5Czx5F"
      },
      "source": [
        "## basic code definitions\n",
        "Enter the cell below and press play or Ctrl+Enter in the block below to execute. You should see the message \"Definitions executed\" printed after execution. (<5 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arbQedj7cIF0"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "from google.colab import drive\n",
        "from random import randint\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import pickle\n",
        "import urllib3\n",
        "import subprocess\n",
        "import os\n",
        "import pandas\n",
        "\n",
        "from tensorflow.keras import models, callbacks, Model, Input, utils, metrics\n",
        "from tensorflow.keras.layers import Conv1D, Dropout, Flatten, Dense, concatenate\n",
        "\n",
        "eLENGTH30 = 30\n",
        "eDEPTH = 4\n",
        "\n",
        "# Function to convert DNA sequence to one-hot encoding\n",
        "def onehot(x):\n",
        "    z = list()\n",
        "    for y in list(x):\n",
        "        if y in \"Aa\":\n",
        "            z.append(0)\n",
        "        elif y in \"Cc\":\n",
        "            z.append(1)\n",
        "        elif y in \"Gg\":\n",
        "            z.append(2)\n",
        "        elif y in \"TtUu\":\n",
        "            z.append(3)\n",
        "        else:\n",
        "            print(\"Non-ATGCU character in\", x)\n",
        "            raise Exception\n",
        "    return z\n",
        "\n",
        "# Function to set the data into the appropriate format\n",
        "def set_data(DX, s):\n",
        "    if s is None:\n",
        "        return\n",
        "    for j, x in enumerate(onehot(s)):\n",
        "        DX[j][x] = 1\n",
        "\n",
        "\n",
        "# Preprocessing function for the sequence data\n",
        "def preprocess_seq(data):\n",
        "    DATA_X30 = np.zeros((len(data), eLENGTH30, eDEPTH), dtype=np.float32)  # onehot\n",
        "    DATA_G = np.zeros((len(data), 1), dtype=np.float32)  # deltaGb\n",
        "    DATA_Y = np.zeros((len(data)), dtype=np.float32)  # efficiency\n",
        "\n",
        "    for l, d in enumerate(data):\n",
        "        set_data(DATA_X30[l], d[1])\n",
        "        DATA_G[l] = -d[2]\n",
        "        DATA_Y[l] = d[3]\n",
        "    return (DATA_X30, DATA_G, DATA_Y)\n",
        "#commands run to download data\n",
        "#You may need to change the URL to a suitable one outside of github due to ratelimits\n",
        "! [[ -e training_data.csv ]] || curl -o training_data.csv https://rth.dk/internal/index.php/s/oF43QXcsLPn7nRL/download\n",
        "! [[ -e validation_data.csv ]] || curl -o validation_data.csv https://rth.dk/internal/index.php/s/kdiXC3XaHLxpwwJ/download\n",
        "print('\\n\\nDefinitions executed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBv98ysX3l3f"
      },
      "source": [
        "## Exercise 1.1 (<5minutes)\n",
        "The sequence of the ontarget of an example gRNA (ACTGAAAAAACCCCCTTTTT), needs to be onehot encoded. An example ontarget of ACTGAAAAAACCCCCTTTTT is TTTTACTGAAAAAACCCCCTTTTTGGGAAA, which includes a four nucleotide prefix, the ontarget to the gRNA, the PAM sequnce and a four nucleotide suffix.\n",
        "\n",
        "Mark the prefix(4nt), on-target(20nt), PAM(3nt), and suffix (4nt) in the ontarget?\n",
        "\n",
        "Use the onehot function defined above to get the encoding of ACTGAAAAAACCCCCTTTTT?\n",
        "\n",
        "Is this what a onehot encoding is supposed to look like, and what could be wrong with encoding the sequence this way?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer"
      ],
      "metadata": {
        "id": "VU23sUuMiKh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjTRRdqs0lUm"
      },
      "source": [
        "\n",
        "## Exercise 1.2 (<5 minutes)\n",
        "Excecute the code below to load the data into the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkEJFEAFcSvC"
      },
      "outputs": [],
      "source": [
        "# x30 - onehot encoded 30mer\n",
        "# g - deltaGb\n",
        "# y - the efficiency value [0-100] )\n",
        "\n",
        "# Training Data\n",
        "PATH = './'\n",
        "d = pandas.read_csv(PATH + 'training_data.csv').values.tolist()\n",
        "(x30, g, y) = preprocess_seq(d)\n",
        "\n",
        "#Validation data read\n",
        "dv = pandas.read_csv(PATH + 'validation_data.csv').values.tolist()\n",
        "(x30v, gv, yv) = preprocess_seq(dv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU_bUo-H2YPV"
      },
      "source": [
        "### Exercise 1.2.1  (<5 minutes)\n",
        "Get the first value of the raw unprocessed training data (d[0]) and the first values of the processed data (x30, g, y). Is this what you expected for the onehot encoding?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer"
      ],
      "metadata": {
        "id": "vR3MZ4P3jLd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XNx_2qf8-20"
      },
      "source": [
        "### Exercise 1.2.2 Model definition (5-10 minutes)\n",
        "In the code below, a simplified version of the CRISPRon ontarget model is defined. Review the code without diving into the details. Then execute it to load the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP9Bn2E9fmgs"
      },
      "outputs": [],
      "source": [
        "\n",
        "OPT = 'adam' #use the ADAM optizer\n",
        "LOSS = 'mse' #loss function is mean squared error\n",
        "\n",
        "DROPOUT_DENSE = 0.3\n",
        "\n",
        "\n",
        "CONV_1_SIZE = 3\n",
        "N_CONV_1 = 40\n",
        "N_DENSE = 40\n",
        "N_OUT = 40\n",
        "\n",
        "# Inputs\n",
        "inputs_30 = list()\n",
        "\n",
        "inputs_c_30 = Input(shape=(eLENGTH30, eDEPTH), name=\"inputs_onehot_30\")\n",
        "inputs_30.append(inputs_c_30)\n",
        "\n",
        "inputs_g = Input(shape=(1,), name=\"inputs_dgb_on\")\n",
        "inputs_30.append(inputs_g)\n",
        "\n",
        "# Model_30 layers\n",
        "for_dense_30 = list()\n",
        "\n",
        "# First convolution layer\n",
        "conv1_out_30 = Conv1D(N_CONV_1, CONV_1_SIZE, activation='relu', input_shape=(eLENGTH30, eDEPTH), name=\"conv_3_30\")(inputs_c_30)\n",
        "conv1_flatten_out_30 = Flatten(name=\"flatten_3_30\")(conv1_out_30)\n",
        "for_dense_30.append(conv1_flatten_out_30)\n",
        "\n",
        "# Concatenation of conv layers and deltaGb layer\n",
        "concat_out_30 = concatenate(for_dense_30, name=\"concat_cnv_30\")\n",
        "\n",
        "# First dense (fully connected) layer\n",
        "dense0_out_30 = Dense(N_DENSE, activation='relu', name=\"dense_0_30\")(concat_out_30)\n",
        "dense0_dropout_out_30 = Dropout(DROPOUT_DENSE, name=\"drop_d0_30\")(dense0_out_30)\n",
        "\n",
        "# Gb input used raw\n",
        "concat1_out_30 = concatenate((inputs_g, dense0_dropout_out_30), name=\"concat_dgb_30\")\n",
        "\n",
        "# First dense (fully connected) layer\n",
        "dense1_out_30 = Dense(N_DENSE, activation='relu', name=\"dense_1_30\")(concat1_out_30)\n",
        "dense1_dropout_out_30 = Dropout(DROPOUT_DENSE, name=\"drop_d1_30\")(dense1_out_30)\n",
        "\n",
        "# Second dense (fully connected) layer\n",
        "dense2_out_30 = Dense(N_OUT, activation='relu', name=\"dense_2_30\")(dense1_dropout_out_30)\n",
        "dense2_dropout_out_30 = Dropout(DROPOUT_DENSE, name=\"drop_d2_30\")(dense2_out_30)\n",
        "\n",
        "# Output layer\n",
        "dense_on_off_out = Dense(N_OUT, activation='relu', name=\"dense_on_off\")(dense2_dropout_out_30)\n",
        "dense_on_off_dropout_out = Dropout(DROPOUT_DENSE, name=\"drop_d_on_off\")(dense_on_off_out)\n",
        "output_30 = Dense(1, name=\"output_30\")(dense_on_off_dropout_out)\n",
        "\n",
        "# Model_30\n",
        "postfix = '.model_30'\n",
        "inputs = inputs_30\n",
        "outputs = [output_30]\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss=LOSS, optimizer=OPT, metrics=['mae', 'mse'])\n",
        "model.is_trained = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP4IwB7e9pfo"
      },
      "source": [
        "### Exercise 1.2.3   (<10 minutes)\n",
        "Use model.summary and keras.utils.plot_model to review the model details. Where are inputs and outputs. Identify the convolutional and multi-layer perceptron parts of the model. Wheres is the Î”Gb input inserted into the model?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer"
      ],
      "metadata": {
        "id": "vbIz9jqEjY37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUiH-5qVUG8e"
      },
      "source": [
        "### Exercise 1.2.4 Model training (10 minutes)\n",
        "Below you will find code for training the simplified CRISPRon model on the provided training data, using the validation data for model evaluation during training. Familiarize yourself with the code and parameters.\n",
        "\n",
        "What is the difference between BATCH_SIZE and epochs?\n",
        "\n",
        "Execute the model **training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6T5hNSajv6b"
      },
      "outputs": [],
      "source": [
        "print(\"training...\")\n",
        "\n",
        "OPT = 'adam' #use the ADAM optizer\n",
        "LEARN = 1e-4 #learning rate\n",
        "EPOCHS = 200 #maximum number of Epochs\n",
        "LOSS = 'mse' #loss function is mean squared error\n",
        "BATCH_SIZE = 64 #batch size for the training\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    (x30, g), y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=((x30v,gv), yv),\n",
        "    callbacks=[\n",
        "        #early stopping is a way to control for overfitting and save the best model\n",
        "        callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            min_delta=0.1,\n",
        "            patience=25,\n",
        "            verbose=1,\n",
        "            mode='auto',\n",
        "            restore_best_weights=True,\n",
        "            ),\n",
        "\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "try:\n",
        "  assert(model.is_trained == False)\n",
        "except:\n",
        "  print(\"Warning: The model was already trained, you need to re-execute the model definition in Exercise 1.2.2 to restart the training\")\n",
        "\n",
        "model.is_trained = True\n",
        "\n",
        "print(\"done\")\n",
        "model.evaluate((x30v, gv), yv )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi5dRvlgXb6E"
      },
      "source": [
        "### Exercise 1.2.4.1 (15 minutes)\n",
        "How many epochs did the code use before it stopped?\n",
        "\n",
        "When did the training reach the optimimal model?\n",
        "\n",
        "Does the code output the exact same performance if you run it twice? Why / Why not?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer"
      ],
      "metadata": {
        "id": "-MR0Nb0elVVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1.2.4.2\n",
        "Repeat the model initialization in (1.2.2) and the model training (1.2.4) 3-5 times and record the performance on the validation data each time.\n",
        "\n",
        "For the best model you obtain, compare the mean squared error and mean absolute error on the validation data with the errors obtained for the **full model** trained on the same data (**mae 9.1, mse 141.3** for the **full model** which is based on the same principles, but contains more and larger layers)?"
      ],
      "metadata": {
        "id": "9Tqr4N8nTMAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# answer"
      ],
      "metadata": {
        "id": "TqUBD3rFTLWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfBPA860iiUi"
      },
      "source": [
        "### Exercise 1.2.5 (if time allows)\n",
        "Play with the model and parameters to get a better performance.\n",
        "\n",
        "Can you beat the full the model performance?\n",
        "\n",
        "What would be the proper way to **test** that?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer\n"
      ],
      "metadata": {
        "id": "xx_8NOAUlW3Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
