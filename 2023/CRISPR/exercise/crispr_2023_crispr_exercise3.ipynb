{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "_VlCGr5Czx5F"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutions in CRISPR on-target\n",
        "Below you will find the third excercise.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/2023/CRISPR/exercise/crispr_2023_crispr_exercise3.ipynb)\n",
        "\n",
        "In this exercise we will take a look at what are the actual outcome of the convolutions of the on-target sequence in the deep learning model.\n",
        "\n",
        "In the code below, we will re-use the simplified version of the CRISPRon ontarget model we created in the previous exercise, however we have reduced the number of convolutions to 10."
      ],
      "metadata": {
        "id": "kgxfc01DPsu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## basic code definitions\n",
        "Enter the cell below and press play or Ctrl+Enter in the block below to execute. You should see the message \"Definitions executed\" printed after execution."
      ],
      "metadata": {
        "id": "_VlCGr5Czx5F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arbQedj7cIF0"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "from google.colab import drive\n",
        "from random import randint\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import pickle\n",
        "import urllib3\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import models, callbacks, Model, Input, utils, metrics\n",
        "from tensorflow.keras.layers import Conv1D, Dropout, AveragePooling1D, Flatten, Dense, concatenate, SpatialDropout1D\n",
        "\n",
        "eLENGTH30 = 30\n",
        "eDEPTH = 4\n",
        "# Function to onehot encode the data\n",
        "def onehot(x):\n",
        "    z = list()\n",
        "    for y in list(x):\n",
        "        if y in \"Aa\":\n",
        "            z.append(0)\n",
        "        elif y in \"Cc\":\n",
        "            z.append(1)\n",
        "        elif y in \"Gg\":\n",
        "            z.append(2)\n",
        "        elif y in \"TtUu\":\n",
        "            z.append(3)\n",
        "        else:\n",
        "            print(\"Non-ATGCU character in\", x)\n",
        "            raise Exception\n",
        "    return z\n",
        "\n",
        "# Function to set the data into the appropriate format\n",
        "def set_data(DX, s, mask=None):\n",
        "  #mask should be a list length len(s) consisting of 1s and 0s, only positions where mask is 0 will be onehot encoded, those with 1s will be masked out.\n",
        "    if s is None:\n",
        "        return\n",
        "    assert(mask==None or (type(mask) is list and len(mask) == len(s)))\n",
        "    if type(mask) is list:\n",
        "        for j, x in enumerate(onehot(s)):\n",
        "            if mask[j] == 0:\n",
        "                DX[j][x] = 1\n",
        "    else:\n",
        "        for j, x in enumerate(onehot(s)):\n",
        "            DX[j][x] = 1\n",
        "\n",
        "\n",
        "# Preprocessing function for the sequence data\n",
        "def preprocess_seq(data, mask=None, use_dgb=True):\n",
        "    DATA_X30 = np.zeros((len(data), eLENGTH30, eDEPTH), dtype=np.float32)  # onehot\n",
        "    DATA_G = np.zeros((len(data), 1), dtype=np.float32)  # deltaGb\n",
        "    DATA_Y = np.zeros((len(data)), dtype=np.float32)  # efficiency\n",
        "\n",
        "    for l, d in enumerate(data):\n",
        "        set_data(DATA_X30[l], d[0], mask)\n",
        "        if use_dgb:\n",
        "            DATA_G[l] = -d[1]\n",
        "        DATA_Y[l] = d[2]\n",
        "    return (DATA_X30, DATA_G, DATA_Y)\n",
        "\n",
        "print(\"Definitions executed\")\n",
        "\n",
        "#commands run to download data\n",
        "! curl -o training_data.pickle https://rth.dk/~anthon/CRISPRsummerschool/2023/CRISPR/exercise/training_data.pickle\n",
        "! curl -o validation_data.pickle https://rth.dk/~anthon/CRISPRsummerschool/2023/CRISPR/exercise/validation_data.pickle\n",
        "\n",
        "# Training Data\n",
        "PATH = './'\n",
        "with open(PATH+'/training_data.pickle', 'rb') as f:\n",
        "    d = pickle.load(f)\n",
        "\n",
        "#Validation data read\n",
        "with open(PATH+'/validation_data.pickle', 'rb') as f:\n",
        "    dv = pickle.load(f)\n",
        "\n",
        "print('Data loaded')\n",
        "OPT = 'adam' #use the ADAM optizer\n",
        "LOSS = 'mse' #loss function is mean squared error\n",
        "\n",
        "DROPOUT_CNV = 0.0\n",
        "DROPOUT_DENSE = 0.3\n",
        "\n",
        "\n",
        "CONV_1_SIZE = 3\n",
        "N_CONV_1 = 10\n",
        "N_DENSE = 40\n",
        "N_OUT = 40\n",
        "\n",
        "# Inputs\n",
        "inputs_30 = list()\n",
        "\n",
        "inputs_c_30 = Input(shape=(eLENGTH30, eDEPTH), name=\"inputs_onehot_30\")\n",
        "inputs_30.append(inputs_c_30)\n",
        "inputs_g = Input(shape=(1), name=\"inputs_dgb_on\")\n",
        "inputs_30.append(inputs_g)\n",
        "\n",
        "# Model_30 layers\n",
        "for_dense_30 = list()\n",
        "\n",
        "# First convolution layer\n",
        "conv1_out_30 = Conv1D(N_CONV_1, CONV_1_SIZE, activation='relu', input_shape=(eLENGTH30, eDEPTH), name=\"conv_3_30\")(inputs_c_30)\n",
        "conv1_flatten_out_30 = Flatten(name=\"flatten_3_30\")(conv1_out_30)\n",
        "for_dense_30.append(conv1_flatten_out_30)\n",
        "\n",
        "# Concatenation of conv layers and deltaGb layer\n",
        "concat_out_30 = concatenate(for_dense_30, name=\"concat_cnv_30\")\n",
        "\n",
        "# First dense (fully connected) layer\n",
        "dense0_out_30 = Dense(N_DENSE, activation='relu', name=\"dense_0_30\")(concat_out_30)\n",
        "dense0_dropout_out_30 = Dropout(DROPOUT_DENSE, name=\"drop_d0_30\")(dense0_out_30)\n",
        "\n",
        "# Gb input used raw\n",
        "concat1_out_30 = concatenate((inputs_g, dense0_dropout_out_30), name=\"concat_dgb_30\")\n",
        "\n",
        "# First dense (fully connected) layer\n",
        "dense1_out_30 = Dense(N_DENSE, activation='relu', name=\"dense_1_30\")(concat1_out_30)\n",
        "dense1_dropout_out_30 = Dropout(DROPOUT_DENSE, name=\"drop_d1_30\")(dense1_out_30)\n",
        "\n",
        "# Second dense (fully connected) layer\n",
        "dense2_out_30 = Dense(N_OUT, activation='relu', name=\"dense_2_30\")(dense1_dropout_out_30)\n",
        "dense2_dropout_out_30 = Dropout(DROPOUT_DENSE, name=\"drop_d2_30\")(dense2_out_30)\n",
        "\n",
        "# Output layer\n",
        "dense_on_off_out = Dense(N_OUT, activation='relu', name=\"dense_on_off\")(dense2_dropout_out_30)\n",
        "dense_on_off_dropout_out = Dropout(DROPOUT_DENSE, name=\"drop_d_on_off\")(dense_on_off_out)\n",
        "output_30 = Dense(1, name=\"output_30\")(dense_on_off_dropout_out)\n",
        "\n",
        "# Model_30\n",
        "postfix = '.model_30'\n",
        "inputs = inputs_30\n",
        "outputs = [output_30]\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss=LOSS, optimizer=OPT, metrics=['mae', 'mse'])\n",
        "model.summary()\n",
        "\n",
        "print('Model defined')\n",
        "\n",
        "\n",
        "#training data preprocess\n",
        "(x30, g, y) = preprocess_seq(d)\n",
        "#Validation data preprocess\n",
        "(x30v, gv, yv) = preprocess_seq(dv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Excercise 3.1 Model definition and convolutions\n",
        "Look at the model summary in the output above.\n",
        "\n",
        "What is the dimensions (shape) of the output of the convolutional layer?\n",
        "\n",
        "How does the output shape relate to the input shape, the size of the convolutions, and to the number of convolutions? (*Hint patching*)\n"
      ],
      "metadata": {
        "id": "_XNx_2qf8-20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer"
      ],
      "metadata": {
        "id": "pbSquDujGZpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3.2 Model training\n",
        "\n",
        "Execute the model **training** to initialize weights for later use. Check that you get more or less the same result as in exercise 1."
      ],
      "metadata": {
        "id": "TUiH-5qVUG8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"training...\")\n",
        "\n",
        "OPT = 'adam' #use the ADAM optizer\n",
        "LEARN = 1e-4 #learning rate\n",
        "EPOCHS = 200 #maximum number of Epochs\n",
        "LOSS = 'mse' #loss function is mean squared error\n",
        "BATCH_SIZE = 64 #batch size for the traing\n",
        "\n",
        "\n",
        "#early stopping is a way to control for overfitting and save the best model\n",
        "es = callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            min_delta=0.1,\n",
        "            patience=25,\n",
        "            verbose=1,\n",
        "            mode='auto',\n",
        "            restore_best_weights=True,\n",
        "            ),\n",
        "\n",
        "#save the initial weights to be able restart the training using the same weights each time\n",
        "model.save_weights('model_30.init.h5')\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    (x30, g), y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=((x30v,gv), yv),\n",
        "    callbacks=[es],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "print(\"done\")\n",
        "\n",
        "print(\"evaluating validation data using best model weights\")\n",
        "model.evaluate((x30v,gv), yv)\n"
      ],
      "metadata": {
        "id": "U6T5hNSajv6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercise 3.3\n",
        "Use ``` tf.keras.Model.get_layer``` to get the convolutional layer above by name and ``` tf.keras.layers.Layer.get_weights```to get the convolutional kernel weights of the untrained model?\n",
        "\n",
        "The weights are af list of two arrays. The first array is the actual weights, while the second array is the biases, which we can ignore for now. Print the first array from the weights you have just obtained?\n",
        "\n",
        "What is the dimension (shape) of the first of the 10 convolutions? (*Hint you may find it easier to look at the weights after the array has been transposed*)"
      ],
      "metadata": {
        "id": "PHWMzNlIGcCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer"
      ],
      "metadata": {
        "id": "RyzbiNa2MtmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3.4\n",
        "Below we transform the ontarget sequence for the first guide and transform it into a form suitable as input the convolutional layer, which expect an extra dimension to accomodate a list of inputs. That is shape(30,4) for the first input is added a dimension to become shape(1,30,4)"
      ],
      "metadata": {
        "id": "nSmak8Q-Scdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x30[0].shape)\n",
        "x30_0 = x30[0].copy()\n",
        "x30_0 = x30_0.reshape([1, 30, 4])\n",
        "print(x30_0.shape)"
      ],
      "metadata": {
        "id": "ugO_SUn0Jtju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 3.4.1\n",
        "Apply the convolutional layer on the first ontarget sequence (```x30_0```) and examine the result.\n",
        "\n",
        "What is the output dimensions (shape)?\n",
        "\n",
        "Identify the array which is the result of applying the first convolution?\n",
        "\n"
      ],
      "metadata": {
        "id": "0T90sU7zT01m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer"
      ],
      "metadata": {
        "id": "TBbiFo-Na5Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we define a very simple convolutional layer with just one convolution of size 3 without biases"
      ],
      "metadata": {
        "id": "UXEVz-2Ua4kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#array defining the weights and biases (not used)\n",
        "w = [np.array([\n",
        "    [[ 0.5], [ 0.0], [ 0.0], [ 0.0]],\n",
        "    [[ 0.5], [ 0.0], [ 0.0], [ 0.0]],\n",
        "    [[ 0.0], [ 0.0], [ 0.0], [ 0.0]]])]\n",
        "print(w[0].transpose())\n",
        "#define a simple convolutional layer with just one convolution of size 3\n",
        "conv_simple_1_3 = tf.keras.layers.Conv1D(1, 3, use_bias=False, input_shape=(30,4))\n",
        "#set the weights using the array defined above\n",
        "conv_simple_1_3.set_weights(w)"
      ],
      "metadata": {
        "id": "Jmg2mf88WTHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Excercise 3.4.2\n",
        "Apply the simple convolution defined above on the first ontarget ```(x30_0)``` and relate the result to the input sequence of the first ontarget?\n",
        "\n",
        "Convolutions are sometimes called filters. How does your observation of the result of the convolution match up with that?"
      ],
      "metadata": {
        "id": "8xcRiTdXbi9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer"
      ],
      "metadata": {
        "id": "geQNCVWqWWZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercise 3.5\n",
        "Convolutions are just one way of finding patterns and features of the inputs in deep learning. One of the latest / greatest invention in the area of deep learning is the natural language processing models like e.g. ```BERT```.\n",
        "\n",
        "What is the philosophy behind natural language processing?\n",
        "\n",
        "Do you think that fx natural language processing or LSTM models are suitable for CRISPR ontarget modeling\n",
        "\n",
        "And what about for CRISPR offtarget and specificity modeling?\n",
        "\n"
      ],
      "metadata": {
        "id": "CuVdcRzgc1n6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer"
      ],
      "metadata": {
        "id": "FoNrT4foZTlw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}